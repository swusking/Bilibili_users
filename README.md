# Bilibili_users
抓取bilibili 一亿用户

### 目录结构  
  + bilibili：存放主要的抓取代码   
    + spider_users.py：采用多线程的爬虫  
    + spider_users_process.py：采用多进程的爬虫  
  + proxy_ip：这里是为了获取代理IP的，网站是一个国外的网站，需要翻墙，当然自己也可以去网站找代理IP，用静态贴上去  
    + getProxy.py：采用多线程获取代理IP
    + getProxy_Process：采用多线程获取代理IP

##### 新手爬虫，高手勿喷。  
这是我的第一个爬虫示例，我打算抓取bilibili一亿用户的数据（截止2017-3-31 Bilibili用户达到一亿），所以我这是目前算是抓取所有用户数据了，并用于分析用户的组成。    
目前我的这个程序抓一万的用户都要用半个小时，感觉效率太低了。但是还是把我的思路都共享出来和大家分享。当然我会继续优化，最终能够实现自己的目标。

关于我既使用了多线程又使用了多进程，我可能因为是新手，刚开始用多线程的时候发现越到后面，线程数越来越少，直到程序开始卡死不动，我就觉得有问题。但使用了多进程之后，没有了这个现象。百度了以后发现多线程是采用的GIL全局解释锁的东西，虽然是多进程但只是用一个CPU核，其实也是线性不是并发的。多进程是并发的。

##### 目前用到的知识  
+ 使用Request请求网页数据，会分析HTTP协议，构造协议头  
+ 使用Queue构造多线程池  
+ 使用MySQLdb和MySQL数据库进行连接并存放数据  
+ 使用PooledDB构建和数据库连接的连接池  
+ 使用multiprocessing构建多进程池
